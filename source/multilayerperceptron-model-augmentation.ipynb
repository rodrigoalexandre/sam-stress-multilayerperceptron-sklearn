{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42175028",
   "metadata": {},
   "source": [
    "#### Carregar o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b43ccbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.utils import resample\n",
    "\n",
    "df = pd.read_csv('../dataset/preprocessed-sam-dataset.csv', sep='|',\n",
    "                 dtype = {'CZ': 'float32', 'FZ': 'float32', 'Fp1': 'float32', 'F3': 'float32',\n",
    "                          'FC1': 'float32', 'FC5': 'float32', 'FT9': 'float32', 'T7': 'float32',\n",
    "                          'CP5': 'float32', 'P3': 'float32', 'P7': 'float32', 'PO9': 'float32',\n",
    "                          'PZ': 'float32', 'O2': 'float32', 'P4': 'float32', 'CP6': 'float32',\n",
    "                          'FT10': 'float32', 'FC6': 'float32', 'F8': 'float32', 'Fp2': 'float32',\n",
    "                          'Scale': 'int8'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d03541",
   "metadata": {},
   "source": [
    "#### Size do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d243cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140800, 21)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fe19a6",
   "metadata": {},
   "source": [
    "#### Executar data augmentation no dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "877e69fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (11000000, 21)\n",
      "0     1000000\n",
      "1     1000000\n",
      "2     1000000\n",
      "3     1000000\n",
      "4     1000000\n",
      "5     1000000\n",
      "6     1000000\n",
      "7     1000000\n",
      "8     1000000\n",
      "9     1000000\n",
      "10    1000000\n",
      "Name: Scale, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_list = []\n",
    "\n",
    "for count in range(0, 11) :\n",
    "    df_list.append(df[df.iloc[:, 20] == count])\n",
    "\n",
    "df_result = pd.DataFrame(columns = ['CZ', 'FZ', 'Fp1', 'F3', 'FC1', 'FC5', 'FT9', 'T7',\n",
    "                          'CP5', 'P3', 'P7', 'PO9', 'PZ', 'O2', 'P4', 'CP6',\n",
    "                          'FT10', 'FC6', 'F8', 'Fp2', 'Scale'])\n",
    "\n",
    "for count in range(0, 11) :\n",
    "    df_upsampled = resample(df_list[count], replace = True, n_samples = 1000000,\n",
    "                            stratify = df_list[count])\n",
    "    df_result = pd.concat([df_result, df_upsampled])\n",
    "\n",
    "print(\"Dataset shape: {}\".format(df_result.shape))\n",
    "\n",
    "print(df_result.Scale.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ceedd9b",
   "metadata": {},
   "source": [
    "#### Treinar o modelo e exibir métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df6c19c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.29378419\n",
      "Validation score: 0.180595\n",
      "Iteration 2, loss = 2.27215570\n",
      "Validation score: 0.183006\n",
      "Iteration 3, loss = 2.26679263\n",
      "Validation score: 0.183538\n",
      "Iteration 4, loss = 2.26411209\n",
      "Validation score: 0.184887\n",
      "Iteration 5, loss = 2.26251455\n",
      "Validation score: 0.187421\n",
      "Iteration 6, loss = 2.26147135\n",
      "Validation score: 0.188327\n",
      "Iteration 7, loss = 2.26076799\n",
      "Validation score: 0.187970\n",
      "Iteration 8, loss = 2.26011404\n",
      "Validation score: 0.187557\n",
      "Iteration 9, loss = 2.25965360\n",
      "Validation score: 0.186535\n",
      "Iteration 10, loss = 2.25925333\n",
      "Validation score: 0.189538\n",
      "Iteration 11, loss = 2.25881073\n",
      "Validation score: 0.188352\n",
      "Iteration 12, loss = 2.25849534\n",
      "Validation score: 0.189135\n",
      "Iteration 13, loss = 2.25825464\n",
      "Validation score: 0.189739\n",
      "Iteration 14, loss = 2.25810439\n",
      "Validation score: 0.188799\n",
      "Iteration 15, loss = 2.25792420\n",
      "Validation score: 0.190117\n",
      "Iteration 16, loss = 2.25775272\n",
      "Validation score: 0.188290\n",
      "Iteration 17, loss = 2.25764129\n",
      "Validation score: 0.190825\n",
      "Iteration 18, loss = 2.25759541\n",
      "Validation score: 0.188618\n",
      "Iteration 19, loss = 2.25748805\n",
      "Validation score: 0.188534\n",
      "Iteration 20, loss = 2.25734778\n",
      "Validation score: 0.189190\n",
      "Iteration 21, loss = 2.25717703\n",
      "Validation score: 0.190132\n",
      "Iteration 22, loss = 2.25705808\n",
      "Validation score: 0.187916\n",
      "Iteration 23, loss = 2.25697389\n",
      "Validation score: 0.188684\n",
      "Iteration 24, loss = 2.25688688\n",
      "Validation score: 0.188270\n",
      "Iteration 25, loss = 2.25676314\n",
      "Validation score: 0.188858\n",
      "Iteration 26, loss = 2.25669390\n",
      "Validation score: 0.188555\n",
      "Iteration 27, loss = 2.25667819\n",
      "Validation score: 0.187434\n",
      "Iteration 28, loss = 2.25664377\n",
      "Validation score: 0.189865\n",
      "Validation score did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n",
      "Train Accuracy: 19.10 %\n",
      "Test Accuracy: 19.11 %\n",
      "\n",
      "\n",
      "Classifiction Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.08      0.10    300010\n",
      "           1       0.20      0.43      0.27    301279\n",
      "           2       0.16      0.18      0.17    299508\n",
      "           3       0.16      0.06      0.09    300146\n",
      "           4       0.16      0.11      0.13    299687\n",
      "           5       0.13      0.07      0.10    298892\n",
      "           6       0.19      0.11      0.14    300353\n",
      "           7       0.16      0.12      0.14    300178\n",
      "           8       0.18      0.12      0.15    300161\n",
      "           9       0.19      0.29      0.23    300213\n",
      "          10       0.25      0.53      0.33    299573\n",
      "\n",
      "    accuracy                           0.19   3300000\n",
      "   macro avg       0.18      0.19      0.17   3300000\n",
      "weighted avg       0.18      0.19      0.17   3300000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_result.drop('Scale', axis = 1)\n",
    "y = df_result['Scale'].astype('int8') \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "scaler = RobustScaler()\n",
    "scaled_trainX = scaler.fit_transform(X_train)\n",
    "scaled_testX = scaler.transform(X_test)\n",
    "\n",
    "model = MLPClassifier(random_state = 42, hidden_layer_sizes = (100,),\n",
    "                        max_iter = 100, activation = 'relu',\n",
    "                        solver = 'adam', batch_size = 100,\n",
    "                        tol = 0.00001, learning_rate_init = 0.001,\n",
    "                        learning_rate = 'constant',\n",
    "                        early_stopping = True, alpha = 0.0000001,\n",
    "                        verbose = True)\n",
    "\n",
    "model.fit(scaled_trainX, y_train)\n",
    "y_pred = model.predict(scaled_testX)\n",
    "\n",
    "print(\"Train Accuracy: {:.2f} %\".format(model.score(scaled_trainX, y_train) * 100))\n",
    "print(\"Test Accuracy: {:.2f} %\".format(accuracy_score(y_test, y_pred) * 100))\n",
    "print('\\n')\n",
    "print(\"Classifiction Report\")\n",
    "print(classification_report(y_test, y_pred, zero_division = 0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1c3eaf",
   "metadata": {},
   "source": [
    "#### Treinar o modelo utilizando cross validation (10 fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b726231c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 19.07 %\n",
      "Test Accuracy: 19.05 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "X = df_result.drop('Scale', axis = 1)\n",
    "y = df_result['Scale'].astype('int8') \n",
    "\n",
    "model = MLPClassifier(random_state = 42, hidden_layer_sizes = (100,),\n",
    "                        max_iter = 100, activation = 'relu',\n",
    "                        solver = 'adam', batch_size = 100,\n",
    "                        tol = 0.00001, learning_rate_init = 0.001,\n",
    "                        learning_rate = 'adaptive',\n",
    "                        early_stopping = True, alpha = 0.0000001,\n",
    "                        verbose = True)\n",
    "\n",
    "pipeline = Pipeline(steps = [\n",
    "  (\"scaler\", RobustScaler()),  \n",
    "  (\"model\", model)\n",
    "])\n",
    "\n",
    "strat_k_fold = StratifiedKFold(n_splits = 3, shuffle = True, random_state = 42)\n",
    "scores = cross_validate(pipeline, X, y, cv = strat_k_fold, n_jobs = 6, return_train_score = True)\n",
    "\n",
    "print(\"Train Accuracy: {:.2f} %\".format(scores['train_score'].mean() * 100))\n",
    "print(\"Test Accuracy: {:.2f} %\".format(scores['test_score'].mean() * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b093297",
   "metadata": {},
   "source": [
    "#### Treinar o modelo e exibir métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1173f7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.66081497\n",
      "Validation score: 0.615521\n",
      "Iteration 2, loss = 0.91553486\n",
      "Validation score: 0.731934\n",
      "Iteration 3, loss = 0.68395756\n",
      "Validation score: 0.791449\n",
      "Iteration 4, loss = 0.56919546\n",
      "Validation score: 0.812395\n",
      "Iteration 5, loss = 0.50320048\n",
      "Validation score: 0.819009\n",
      "Iteration 6, loss = 0.46212103\n",
      "Validation score: 0.839023\n",
      "Iteration 7, loss = 0.43539686\n",
      "Validation score: 0.853694\n",
      "Iteration 8, loss = 0.41591609\n",
      "Validation score: 0.866001\n",
      "Iteration 9, loss = 0.40266611\n",
      "Validation score: 0.867931\n",
      "Iteration 10, loss = 0.39287366\n",
      "Validation score: 0.874804\n",
      "Iteration 11, loss = 0.38528790\n",
      "Validation score: 0.881238\n",
      "Iteration 12, loss = 0.37835373\n",
      "Validation score: 0.870162\n",
      "Iteration 13, loss = 0.37411638\n",
      "Validation score: 0.893905\n",
      "Iteration 14, loss = 0.36983117\n",
      "Validation score: 0.888092\n",
      "Iteration 15, loss = 0.36727278\n",
      "Validation score: 0.882906\n",
      "Iteration 16, loss = 0.36510958\n",
      "Validation score: 0.881997\n",
      "Iteration 17, loss = 0.36313828\n",
      "Validation score: 0.879690\n",
      "Iteration 18, loss = 0.36143150\n",
      "Validation score: 0.896761\n",
      "Iteration 19, loss = 0.36005604\n",
      "Validation score: 0.886931\n",
      "Iteration 20, loss = 0.35927051\n",
      "Validation score: 0.890456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\DeveloperTools\\anaconda3\\envs\\opencv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 89.89 %\n",
      "Test Accuracy: 89.62 %\n",
      "\n",
      "\n",
      "Classifiction Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.85      0.89    300010\n",
      "           1       0.90      0.90      0.90    301279\n",
      "           2       0.86      0.92      0.89    299508\n",
      "           3       0.90      0.89      0.89    300146\n",
      "           4       0.88      0.90      0.89    299687\n",
      "           5       0.89      0.89      0.89    298892\n",
      "           6       0.93      0.86      0.89    300353\n",
      "           7       0.91      0.91      0.91    300178\n",
      "           8       0.87      0.91      0.89    300161\n",
      "           9       0.91      0.89      0.90    300213\n",
      "          10       0.89      0.95      0.92    299573\n",
      "\n",
      "    accuracy                           0.90   3300000\n",
      "   macro avg       0.90      0.90      0.90   3300000\n",
      "weighted avg       0.90      0.90      0.90   3300000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_result.drop('Scale', axis = 1)\n",
    "y = df_result['Scale'].astype('int8') \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "scaler = RobustScaler()\n",
    "scaled_trainX = scaler.fit_transform(X_train)\n",
    "scaled_testX = scaler.transform(X_test)\n",
    "\n",
    "model = MLPClassifier(random_state = 42, hidden_layer_sizes = (100, 300, 300, 300, 100),\n",
    "                        max_iter = 20, activation = 'relu',\n",
    "                        solver = 'adam', batch_size = 100,\n",
    "                        tol = 0.00001, learning_rate_init = 0.001,\n",
    "                        learning_rate = 'constant',\n",
    "                        early_stopping = True, alpha = 0.0000001,\n",
    "                        verbose = True)\n",
    "\n",
    "model.fit(scaled_trainX, y_train)\n",
    "y_pred = model.predict(scaled_testX)\n",
    "\n",
    "print(\"Train Accuracy: {:.2f} %\".format(model.score(scaled_trainX, y_train) * 100))\n",
    "print(\"Test Accuracy: {:.2f} %\".format(accuracy_score(y_test, y_pred) * 100))\n",
    "print('\\n')\n",
    "print(\"Classifiction Report\")\n",
    "print(classification_report(y_test, y_pred, zero_division = 0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb866c24",
   "metadata": {},
   "source": [
    "#### Treinar o modelo e exibir métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c4ca497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.40404738\n",
      "Validation score: 0.756571\n",
      "Iteration 2, loss = 0.51701186\n",
      "Validation score: 0.863340\n",
      "Iteration 3, loss = 0.32961934\n",
      "Validation score: 0.904308\n",
      "Iteration 4, loss = 0.25709660\n",
      "Validation score: 0.921905\n",
      "Iteration 5, loss = 0.22370169\n",
      "Validation score: 0.931749\n",
      "Iteration 6, loss = 0.20613778\n",
      "Validation score: 0.934939\n",
      "Iteration 7, loss = 0.19646341\n",
      "Validation score: 0.934761\n",
      "Iteration 8, loss = 0.19009077\n",
      "Validation score: 0.939513\n",
      "Iteration 9, loss = 0.18649616\n",
      "Validation score: 0.950226\n",
      "Iteration 10, loss = 0.18386348\n",
      "Validation score: 0.943948\n",
      "Iteration 11, loss = 0.18217685\n",
      "Validation score: 0.947909\n",
      "Iteration 12, loss = 0.18175873\n",
      "Validation score: 0.945912\n",
      "Iteration 13, loss = 0.18106357\n",
      "Validation score: 0.951079\n",
      "Iteration 14, loss = 0.18124807\n",
      "Validation score: 0.955466\n",
      "Iteration 15, loss = 0.18185097\n",
      "Validation score: 0.947378\n",
      "Iteration 16, loss = 0.18150321\n",
      "Validation score: 0.952586\n",
      "Iteration 17, loss = 0.18233813\n",
      "Validation score: 0.956762\n",
      "Iteration 18, loss = 0.18316587\n",
      "Validation score: 0.958226\n",
      "Iteration 19, loss = 0.18406666\n",
      "Validation score: 0.949771\n",
      "Iteration 20, loss = 0.18554988\n",
      "Validation score: 0.950151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\DeveloperTools\\anaconda3\\envs\\opencv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 95.93 %\n",
      "Test Accuracy: 95.83 %\n",
      "\n",
      "\n",
      "Classifiction Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96    300010\n",
      "           1       0.96      0.97      0.96    301279\n",
      "           2       0.95      0.97      0.96    299508\n",
      "           3       0.96      0.95      0.96    300146\n",
      "           4       0.97      0.94      0.96    299687\n",
      "           5       0.95      0.96      0.95    298892\n",
      "           6       0.97      0.95      0.96    300353\n",
      "           7       0.96      0.96      0.96    300178\n",
      "           8       0.96      0.95      0.96    300161\n",
      "           9       0.95      0.97      0.96    300213\n",
      "          10       0.95      0.98      0.96    299573\n",
      "\n",
      "    accuracy                           0.96   3300000\n",
      "   macro avg       0.96      0.96      0.96   3300000\n",
      "weighted avg       0.96      0.96      0.96   3300000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_result.drop('Scale', axis = 1)\n",
    "y = df_result['Scale'].astype('int8') \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "scaler = RobustScaler()\n",
    "scaled_trainX = scaler.fit_transform(X_train)\n",
    "scaled_testX = scaler.transform(X_test)\n",
    "\n",
    "model = MLPClassifier(random_state = 42, hidden_layer_sizes = (100, 300, 500, 300, 100),\n",
    "                        max_iter = 20, activation = 'relu',\n",
    "                        solver = 'adam', batch_size = 100,\n",
    "                        tol = 0.00001, learning_rate_init = 0.001,\n",
    "                        learning_rate = 'constant',\n",
    "                        early_stopping = True, alpha = 0.0000001,\n",
    "                        verbose = True)\n",
    "\n",
    "model.fit(scaled_trainX, y_train)\n",
    "y_pred = model.predict(scaled_testX)\n",
    "\n",
    "print(\"Train Accuracy: {:.2f} %\".format(model.score(scaled_trainX, y_train) * 100))\n",
    "print(\"Test Accuracy: {:.2f} %\".format(accuracy_score(y_test, y_pred) * 100))\n",
    "print('\\n')\n",
    "print(\"Classifiction Report\")\n",
    "print(classification_report(y_test, y_pred, zero_division = 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7c57b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
